{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Sequential Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import operator\n",
    "import gsp as gsp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from fim import apriori\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = 'plots/figure_{}.png'\n",
    "dataFolder = '../../data/{}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    df = pd.read_csv(dataFolder.format('customer_supermarket.csv'), sep='\\t', index_col=0).drop_duplicates()\n",
    "    \n",
    "    df['Sale'] = df['Sale'].str.replace(\",\",\".\").astype(float) # replace ',' with '.' to make Sale type as float64\n",
    "    df['CustomerID'] = df['CustomerID'].astype('Int64')\n",
    "    df['BasketDate'] = pd.to_datetime(df['BasketDate'])\n",
    "    df = df[df['CustomerID'].notna()]\n",
    "    return df\n",
    "\n",
    "def load_customer_baskets():\n",
    "    df = load_dataset()\n",
    "    df = df[['CustomerID','ProdID','BasketID','BasketDate']]\n",
    "    df = df.sort_values(by='BasketDate')\n",
    "    df = df.groupby(['CustomerID','BasketID'])['ProdID'].apply(list).reset_index()\n",
    "    df = df.groupby('CustomerID')['ProdID'].apply(list).reset_index()\n",
    "    customer_baskets = []\n",
    "    for index, row in df.iterrows():\n",
    "        customer_baskets.append({\n",
    "            'customer_id': row['CustomerID'],\n",
    "            'baskets': row['ProdID']\n",
    "        })\n",
    "    return customer_baskets\n",
    "\n",
    "def load_products():\n",
    "    df = load_dataset()\n",
    "    df = df[['ProdID','ProdDescr']]\n",
    "    df.set_index('ProdID', inplace=True)\n",
    "    df = df.groupby('ProdID')['ProdDescr'].agg(list).apply(lambda x: ';'.join(set(x))).reset_index()\n",
    "    products = {}\n",
    "    for index, row in df.iterrows():\n",
    "        products[row['ProdID']] = row['ProdDescr']\n",
    "        \"\"\"products.append({\n",
    "            'prod_id': row['ProdID'],\n",
    "            'prod_descr': row['ProdDescr']\n",
    "        })\"\"\"\n",
    "    return products\n",
    "\n",
    "def load_transactions():\n",
    "    df = load_dataset()\n",
    "    df = df[['BasketID','ProdID','CustomerID']]\n",
    "    df = df.groupby(['BasketID','CustomerID'])['ProdID'].agg(list).reset_index()\n",
    "    transactions = []\n",
    "    for index, row in df.iterrows():\n",
    "        transactions.append({\n",
    "            'basket_id': row['BasketID'],\n",
    "            'customer_id': row['CustomerID'],\n",
    "            'products': row['ProdID']\n",
    "        })\n",
    "    return transactions\n",
    "\n",
    "def get_grid_search(*args):\n",
    "    import itertools\n",
    "    grid = []\n",
    "    for e in itertools.product(*args):\n",
    "        grid.append({\n",
    "            'supp': e[0],\n",
    "            'zmin': e[1],\n",
    "            'conf': e[2]\n",
    "        })\n",
    "    return grid\n",
    "\n",
    "def save(rules, fname):\n",
    "    with open(fname, \"wb\") as f:\n",
    "        pickle.dump(rules, f)\n",
    "            \n",
    "def read(fname):\n",
    "    rules = []\n",
    "    with open(fname, \"rb\") as f:\n",
    "        rules = pickle.load(f)\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset = load_dataset()\n",
    "n_customers = dataset['CustomerID'].nunique()\n",
    "print(f\"Number of customers: {n_customers}\")\n",
    "products = load_products()\n",
    "transactions = load_transactions()\n",
    "baskets = [t['products'] for t in transactions]\n",
    "print(f\"Number of baskets: {len(baskets)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "help(apriori)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "itemsets = apriori(baskets, supp=1, zmin=2, zmax=5, target='a')\n",
    "print('Number of itemsets:', len(itemsets), end='\\n\\n')\n",
    "print(itemsets[:10])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid_search = get_grid_search(\n",
    "    list(np.arange(1, 4)),  # supp values\n",
    "    [2],  # zmin values\n",
    "    list(np.arange(20, 80, 10))  # conf values\n",
    ")\n",
    "\n",
    "history = []\n",
    "\n",
    "with tqdm(total=len(grid_search)) as pbar:\n",
    "    for g in grid_search:\n",
    "        pbar.set_description(f\"{g}\")\n",
    "        supp = g['supp']\n",
    "        zmin = g['zmin']\n",
    "        conf = g['conf']\n",
    "\n",
    "        rules = apriori(baskets, supp=supp, zmin=zmin, target='r', conf=conf, report='ascl')\n",
    "\n",
    "        map_rules = []\n",
    "        for idx, rule in enumerate(rules):\n",
    "            map_rules.append({'id': idx, 'consequent': rule[0], 'antecedents': rule[1], 'abs_supp': rule[2], 'rel_supp': rule[3], 'conf': rule[4], 'lift': rule[5], 'customers': []})\n",
    "\n",
    "        # add affected customer to rules\n",
    "        for rule in map_rules:\n",
    "            premises = rule['antecedents']\n",
    "            consequent = rule['antecedents']\n",
    "            for t in transactions:\n",
    "                basket = t['products']\n",
    "                if (set(premises) < set(basket)) and (set(consequent) < set(basket)):\n",
    "                    if t['customer_id'] not in rule['customers']:\n",
    "                        rule['customers'].append(t['customer_id'])\n",
    "\n",
    "        # count number of customer affected by rules\n",
    "        customers = []\n",
    "        for rule in map_rules:\n",
    "            customers += rule['customers']\n",
    "            customers = list(set(customers))\n",
    "        \n",
    "        #print(f\">> supp={supp}, zmin={zmin}, conf={conf}, customers={len(customers)}/{n_customers}\")\n",
    "        history.append({\n",
    "            'params': g,\n",
    "            'ratio': (len(customers)/n_customers),\n",
    "            'n_rules': len(rules)\n",
    "        })\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "max_conf = max(history, key=lambda x: x['ratio'])\n",
    "print(max_conf)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# returns: (consequent, antecedents, absolute itemset support, relative itemset support, rule confidence, lift value)\n",
    "rules = apriori(baskets, supp=1, zmin=2, target='r', conf=60, report='ascl')\n",
    "print(f\"Number of extracted rules: {len(rules)}\")\n",
    "print(rules[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map the rules and baskets with a unique id"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "map_rules = []\n",
    "for idx, rule in enumerate(rules):\n",
    "    map_rules.append({'id': idx, 'consequent': rule[0], 'antecedents': rule[1], 'abs_supp': rule[2], 'rel_supp': rule[3], 'conf': rule[4], 'lift': rule[5], 'customers': []})\n",
    "print(map_rules[0])\n",
    "\n",
    "map_baskets = []\n",
    "for idx, basket in enumerate(baskets):\n",
    "    map_baskets.append({'id': idx, 'items': basket})\n",
    "print(map_baskets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of the rules confidence"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "confs = [rule['conf'] for rule in map_rules]\n",
    "plt.hist(confs, density=True, bins=int(math.sqrt(len(confs))))\n",
    "plt.ylabel('Num. of rules')\n",
    "plt.xlabel('Confidence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of the rules lifts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lifts = [rule['lift'] for rule in map_rules]\n",
    "plt.hist(lifts, density=True, bins=int(math.sqrt(len(lifts))))\n",
    "plt.ylabel('Num. of rules')\n",
    "plt.xlabel('Lift')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lift_threshold = 15\n",
    "conf_threshold = 0.75\n",
    "filtered_rules = []\n",
    "\n",
    "for rule in map_rules:\n",
    "    lift_value = rule['lift']\n",
    "    conf_value = rule['conf']\n",
    "    if lift_value > lift_threshold and conf_value > conf_threshold:\n",
    "        filtered_rules.append(rule)\n",
    "print(f\"Number of filtered rules: {len(filtered_rules)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the users that contains basket in the premise of a rule"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for rule in filtered_rules:\n",
    "    premises = rule['antecedents']\n",
    "    consequent = rule['antecedents']\n",
    "    for t in transactions:\n",
    "        basket = t['products']\n",
    "        if (set(premises) < set(basket)) and (set(consequent) < set(basket)):\n",
    "            if t['customer_id'] not in rule['customers']:\n",
    "                rule['customers'].append(t['customer_id'])\n",
    "print(filtered_rules[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rules sorted by Confidence"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sorted_rules = sorted(filtered_rules, key=operator.itemgetter('conf'), reverse=True)\n",
    "sorted_rules = sorted_rules[:]\n",
    "for rule in sorted_rules:\n",
    "    print(f\"- Rule: {rule['antecedents']} => {rule['consequent']}, Conf: {rule['conf']}, Lift: {rule['lift']}\", end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rules explained"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for rule in sorted_rules[:]:\n",
    "    antecedents = list(rule['antecedents'])\n",
    "    consequent = rule['consequent']\n",
    "    customers = rule['customers']\n",
    "    a_names = [products[s].split(';')[0] for s in antecedents]\n",
    "    c_name = products[consequent].split(';')[0]\n",
    "    print(f\"- Rule: {a_names} => {c_name}\", end=\"\\n\")\n",
    "    print(f\"\\tCustomers affected by this rule: {customers[:10]}... (of {len(customers)})\", end=\"\\n\\n\")\n",
    "\n",
    "customers = []\n",
    "for rule in sorted_rules:\n",
    "    customers += rule['customers']\n",
    "    customers = list(set(customers))\n",
    "print(f\"Percentage of customers affected by rules: {len(customers)/n_customers}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GSP"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "support = 150\n",
    "dataset = load_customer_baskets()\n",
    "dataset = [c['baskets'] for c in dataset]\n",
    "print(f'Number of transactions: {len(dataset)}')\n",
    "result_set = gsp.apriori(dataset, support, verbose=True)\n",
    "print(f\"Number of rules: {len(result_set)}\")\n",
    "save(result_set, f\"rules_{support}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load rules from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of products: 3684\n"
     ]
    }
   ],
   "source": [
    "f_name = 'rules_200.pkl'\n",
    "products = load_products()\n",
    "print(f\"Number of products: {len(products.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exists!\n",
      "Number of rules: 402\n",
      "Number of filtered rules: 32\n",
      "- Rule: ['CREAM HANGING HEART T-LIGHT HOLDER', 'CREAM HANGING HEART T-LIGHT HOLDER'], sup=416\n",
      "- Rule: ['REGENCY CAKESTAND 3 TIER', 'REGENCY CAKESTAND 3 TIER'], sup=363\n",
      "- Rule: ['JUMBO BAG RED RETROSPOT', 'JUMBO BAG RED RETROSPOT'], sup=317\n",
      "- Rule: ['ASSORTED COLOUR BIRD ORNAMENT', 'ASSORTED COLOUR BIRD ORNAMENT'], sup=294\n",
      "- Rule: ['LUNCH BAG RED SPOTTY', 'LUNCH BAG RED SPOTTY'], sup=284\n",
      "- Rule: ['PARTY BUNTING', 'PARTY BUNTING'], sup=282\n",
      "- Rule: ['SET OF 3 CAKE TINS PANTRY DESIGN ', 'SET OF 3 CAKE TINS PANTRY DESIGN '], sup=249\n",
      "- Rule: ['JUMBO BAG RED RETROSPOT', 'JUMBO BAG VINTAGE DOILY '], sup=237\n",
      "- Rule: ['JUMBO BAG VINTAGE DOILY ', 'JUMBO BAG VINTAGE DOILY '], sup=236\n",
      "- Rule: ['LUNCH BAG  BLACK SKULL.', 'LUNCH BAG  BLACK SKULL.'], sup=233\n",
      "- Rule: ['LUNCH BAG SUKI DESIGN ', 'LUNCH BAG SUKI DESIGN '], sup=230\n",
      "- Rule: ['CREAM HANGING HEART T-LIGHT HOLDER', 'CREAM HANGING HEART T-LIGHT HOLDER', 'CREAM HANGING HEART T-LIGHT HOLDER'], sup=230\n",
      "- Rule: ['LUNCH BAG RED SPOTTY', 'LUNCH BAG  BLACK SKULL.'], sup=215\n",
      "- Rule: ['LUNCH BAG RED SPOTTY', 'LUNCH BAG VINTAGE DOILY '], sup=213\n",
      "- Rule: ['REGENCY CAKESTAND 3 TIER', 'SET OF 3 REGENCY CAKE TINS'], sup=213\n",
      "- Rule: ['LUNCH BAG CARS BLUE', 'LUNCH BAG RED SPOTTY'], sup=212\n",
      "- Rule: ['BUNTING , SPOTTY ', 'BUNTING , SPOTTY '], sup=212\n",
      "- Rule: ['LUNCH BAG  BLACK SKULL.', 'LUNCH BAG RED SPOTTY'], sup=211\n",
      "- Rule: ['LUNCH BAG CARS BLUE', 'LUNCH BAG CARS BLUE'], sup=210\n",
      "- Rule: ['LUNCH BAG RED SPOTTY', 'LUNCH BAG SPACEBOY DESIGN '], sup=209\n",
      "- Rule: ['LUNCH BAG VINTAGE DOILY ', 'LUNCH BAG VINTAGE DOILY '], sup=209\n",
      "- Rule: ['LUNCH BAG RED SPOTTY', 'LUNCH BAG SUKI DESIGN '], sup=208\n",
      "- Rule: ['JUMBO BAG VINTAGE DOILY ', 'JUMBO BAG RED RETROSPOT'], sup=206\n",
      "- Rule: ['LUNCH BAG PINK POLKADOT', 'LUNCH BAG RED SPOTTY'], sup=204\n",
      "- Rule: ['JUMBO BAG RED RETROSPOT', 'LUNCH BAG RED SPOTTY'], sup=204\n",
      "- Rule: ['HEART OF WICKER SMALL', 'HEART OF WICKER SMALL'], sup=203\n",
      "- Rule: ['SMALL POPCORN HOLDER', 'SMALL POPCORN HOLDER'], sup=202\n",
      "- Rule: ['LUNCH BAG PINK POLKADOT', 'LUNCH BAG PINK POLKADOT'], sup=202\n",
      "- Rule: ['LUNCH BAG RED SPOTTY', 'JUMBO BAG RED RETROSPOT'], sup=201\n",
      "- Rule: ['LUNCH BAG SPACEBOY DESIGN ', 'LUNCH BAG RED SPOTTY'], sup=201\n",
      "- Rule: ['LUNCH BAG SPACEBOY DESIGN ', 'LUNCH BAG SPACEBOY DESIGN '], sup=201\n",
      "- Rule: ['POSTAGE', 'POSTAGE'], sup=201\n"
     ]
    }
   ],
   "source": [
    "rules = []\n",
    "\n",
    "if os.path.isfile(f_name):\n",
    "    print('file exists!')\n",
    "    rules = read(f_name)\n",
    "print(f\"Number of rules: {len(rules)}\")\n",
    "\n",
    "filtered_rules = []\n",
    "for r in rules:\n",
    "    if len(r[0]) > 1:\n",
    "        filtered_rules.append(r)\n",
    "print(f\"Number of filtered rules: {len(filtered_rules)}\")\n",
    "\n",
    "filtered_rules = sorted(filtered_rules, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for rule in filtered_rules:\n",
    "    sequence = [s[0] for s in rule[0]]\n",
    "    names = [products[s].split(';')[0] for s in sequence]\n",
    "    print(f\"- Rule: {names}, sup={rule[1]}\", end=\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
