{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Sequential Pattern with Time Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gsp as gsp\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import datetime\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "img = 'plots/figure_{}.png'\n",
    "dataFolder = '../../data/{}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    df = pd.read_csv(dataFolder.format('customer_supermarket.csv'), sep='\\t', index_col=0).drop_duplicates()\n",
    "\n",
    "    df['Sale'] = df['Sale'].str.replace(\",\", \".\").astype(float)  # replace ',' with '.' to make Sale type as float64\n",
    "    df['CustomerID'] = df['CustomerID'].astype('Int64')\n",
    "    df['BasketDate'] = pd.to_datetime(df['BasketDate'])\n",
    "    df = df[df['CustomerID'].notna()]\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_customer_baskets():\n",
    "    df = load_dataset()\n",
    "\n",
    "    df['ProdID'] = df['ProdID'].astype('category')\n",
    "\n",
    "    # Create a dictionary of ProdID (key) and its mapping to an integer as value\n",
    "    prod_n_mapping = dict(zip(df['ProdID'], df['ProdID'].cat.codes))\n",
    "\n",
    "    # Create a dictionary of mapped ProdID to int (key) and its description as value\n",
    "    prod_cat_descr = dict(zip(df['ProdID'].cat.codes, df['ProdDescr']))\n",
    "\n",
    "    df = df[['CustomerID', 'ProdID', 'BasketID', 'BasketDate']]\n",
    "    df = df.sort_values(by='BasketDate')\n",
    "\n",
    "    # Keep only the date (drop time)\n",
    "    df['BasketDate'] = df['BasketDate'].dt.date\n",
    "    df['BasketDate'] = pd.to_datetime(df['BasketDate']).values.astype(np.int64) // 10 ** 9\n",
    "\n",
    "    df['BasketDate'] = df['BasketDate'].astype('category')\n",
    "    df['BasketDate'] = df['BasketDate'].cat.codes\n",
    "\n",
    "    df = df.groupby(['CustomerID', 'BasketID', 'BasketDate'])['ProdID'].apply(list).reset_index()\n",
    "    df = df.groupby(['CustomerID', 'BasketDate'])['ProdID'].apply(list).reset_index()\n",
    "\n",
    "    customer_baskets = {}\n",
    "    for index, row in df.iterrows():\n",
    "        if customer_baskets.__contains__(row['CustomerID']):\n",
    "            baskets_in_dict = customer_baskets[row['CustomerID']]\n",
    "            if baskets_in_dict.__contains__(row['BasketDate']):\n",
    "                a = baskets_in_dict[row['BasketDate']]\n",
    "                a.append(row['ProdID'][0])\n",
    "            else:\n",
    "                baskets_in_dict[row['BasketDate']] = row['ProdID']\n",
    "        else:\n",
    "            customer_baskets[row['CustomerID']] = {row['BasketDate']: row['ProdID']}\n",
    "\n",
    "    return customer_baskets, prod_n_mapping, prod_cat_descr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "The input file format is defined as follows. It is a text file where each line represents a sequence\n",
    "from a sequence database. Each item from a sequence is a positive integer and items from the same \n",
    "itemset within a sequence are separated by single space. Note that it is assumed that items within a\n",
    "same itemset are sorted according to a total order and that no item can appear twice in the same itemset. \n",
    "\n",
    "The value between <> is the timestamp\n",
    "The value \"-1\" indicates the end of an itemset. \n",
    "The value \"-2\" indicates the end of a sequence (it appears at the end of each line). \n",
    "\n",
    "For example, the input file \"contextPrefixSpan.txt\" contains the following four lines (four sequences).\n",
    "\n",
    "    <0> 1 -1 <1> 1 2 3 -1 <2> 1 3 -1 -2\n",
    "    <0> 1 -1 <1> 1 2 -1 <2> 1 2 3 -1 <3> 1 2 3 -1 -2\n",
    "    <0> 1 2 -1 <1> 1 2 -1 -2\n",
    "    <0> 2 -1 <1> 1 2 3 -1 -2\n",
    "\n",
    "The first line represents a sequence where the itemset {1} is followed by the itemset {1, 2, 3}, followed by the itemset {1, 3}, followed by the itemset {4}, followed by the itemset {3, 6}. The next lines follow the same format.\n",
    "\n",
    "\n",
    "@CONVERTED_FROM_TEXT\n",
    "@ITEM=1=apple\n",
    "@ITEM=2=orange\n",
    "@ITEM=3=tomato\n",
    "@ITEM=4=milk\n",
    "@ITEM=5=bread\n",
    "@ITEM=6=noodle\n",
    "@ITEM=7=rice\n",
    "@ITEM=-1=|\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('input_time_constraint.txt'):\n",
    "\n",
    "    gsp_dataset, prod_n_mapping, prod_cat_descr = load_customer_baskets()\n",
    "\n",
    "    # This is to save the mapping between the ProdIDs and their Descriptions\n",
    "    # in order to have a textual description in the end\n",
    "    with open('input_time_constraint.txt', 'w') as f:\n",
    "        f.write('@CONVERTED_FROM_TEXT\\n')\n",
    "        f.write('@ITEM=-1=|\\n')\n",
    "\n",
    "        for k, v in prod_cat_descr.items():\n",
    "            f.write('@ITEM={}={}, \\n'.format(k, v))\n",
    "\n",
    "    # Create the input_time_constraint.txt file that will be passed to the library\n",
    "    with open('input_time_constraint.txt', 'a') as f:\n",
    "\n",
    "        for customer, time_sequences in tqdm.tqdm(gsp_dataset.items()):\n",
    "            string = \"\"\n",
    "\n",
    "            date_start = None\n",
    "\n",
    "            for time, itemsets in time_sequences.items():\n",
    "\n",
    "                data = time\n",
    "\n",
    "                if date_start is None:\n",
    "                    date_start = data\n",
    "                    time_delay = 0\n",
    "\n",
    "                else:\n",
    "                    time_delay = data-date_start  # 0, 3, 6\n",
    "                #print(f\"{customer} {time} {data} {time_delay}\")\n",
    "\n",
    "                string += \"<{}> \".format(time_delay)\n",
    "\n",
    "                for itemset in itemsets:\n",
    "                    for item in sorted(itemset, key=str.lower):\n",
    "                       string += \"{} \".format(prod_n_mapping[item])\n",
    "                    string += \"-1 \"  # The value \"-1\" indicates the end of an itemset.\n",
    "\n",
    "            string += \"-2\"  # The value \"-2\" indicates the end of a sequence (it appears at the end of each line).\n",
    "            f.write(string+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total seconds elapsed 1.675412s\n"
     ]
    }
   ],
   "source": [
    "support_percentage = \"5%\"\n",
    "\n",
    "min_time_interval = 1  # Min Gap\n",
    "max_time_interval = 7  # Max Gap\n",
    "# Max Span\n",
    "min_whole_interval = 0\n",
    "max_whole_interval = 30\n",
    "\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "subprocess.call([\"java\", \"-jar\", \"spmf.jar\", \"run\", \"HirateYamana\", \"input_time_constraint.txt\", \"results_time_constraints/results_support_{}.txt\".format(support_percentage),\n",
    "                 \"{}\".format(support_percentage), \"{}\".format(min_time_interval), \"{}\".format(max_time_interval), \"{}\".format(min_whole_interval), \"{}\".format(max_whole_interval)])\n",
    "end = datetime.datetime.now()\n",
    "print(\"Total seconds elapsed {}s\".format((end-start).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Sequences                                                                                        |   Support |   Num elements |\n",
      "|:-------------------------------------------------------------------------------------------------|----------:|---------------:|\n",
      "| GREEN REGENCY TEACUP AND SAUCER, PINK REGENCY TEACUP AND SAUCER, ROSES REGENCY TEACUP AND SAUCER |       240 |              3 |\n",
      "| GREEN REGENCY TEACUP AND SAUCER, ROSES REGENCY TEACUP AND SAUCER                                 |       313 |              2 |\n",
      "| PAPER CHAIN KIT 50'S CHRISTMAS, PAPER CHAIN KIT VINTAGE CHRISTMAS                                |       313 |              2 |\n",
      "| GREEN REGENCY TEACUP AND SAUCER, PINK REGENCY TEACUP AND SAUCER                                  |       283 |              2 |\n",
      "| HEART OF WICKER SMALL, HEART OF WICKER LARGE                                                     |       277 |              2 |\n",
      "| RED HANGING HEART T-LIGHT HOLDER, CREAM HANGING HEART T-LIGHT HOLDER                             |       273 |              2 |\n",
      "| REGENCY CAKESTAND 3 TIER, ROSES REGENCY TEACUP AND SAUCER                                        |       266 |              2 |\n",
      "| PINK REGENCY TEACUP AND SAUCER, ROSES REGENCY TEACUP AND SAUCER                                  |       257 |              2 |\n",
      "| JUMBO BAG PINK POLKADOT, JUMBO BAG RED RETROSPOT                                                 |       255 |              2 |\n",
      "| LUNCH BAG RED RETROSPOT, LUNCH BAG PINK POLKADOT                                                 |       255 |              2 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-520655ec51ed>:4: DeprecationWarning: 'U' mode is deprecated\n",
      "  with open(\"results_time_constraints/results_support_{}.txt\".format(support_percentage), \"rU\") as f:\n"
     ]
    }
   ],
   "source": [
    "# read output rules\n",
    "lines = []\n",
    "try:\n",
    "    with open(\"results_time_constraints/results_support_{}.txt\".format(support_percentage), \"rU\") as f:\n",
    "        lines = f.readlines()\n",
    "except:\n",
    "    print\n",
    "    \"read_output error\"\n",
    "\n",
    "patterns = []\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    patterns.append(line.split(\" -1 \"))\n",
    "\n",
    "n_pattern_found = 0\n",
    "sequences = []\n",
    "supp = []\n",
    "\n",
    "useful = 0\n",
    "n_elements = []\n",
    "\n",
    "for p in patterns:\n",
    "    p = p[0].split(\",\")\n",
    "\n",
    "    useful += 1\n",
    "\n",
    "    sx_str = \"\"\n",
    "    n_element = len(p)\n",
    "    if n_element > 2:\n",
    "        n_elements.append(n_element-1)\n",
    "        for i, el in enumerate(p):\n",
    "            if i == (n_element-1):\n",
    "                el = el.replace(\"#SUP: \", \"\").replace(\"|\", \"\")\n",
    "                supp.append(int(el))\n",
    "\n",
    "            else:\n",
    "                if sx_str != \"\":\n",
    "                    sx_str += \", \"+el.strip().replace(\"<0>\", \"\")\n",
    "                else:\n",
    "                    sx_str += el.strip().replace(\"<0>\", \"\")\n",
    "\n",
    "        sequences.append(sx_str.strip())\n",
    "        n_pattern_found += 1\n",
    "\n",
    "df = pd.DataFrame({'Sequences': sequences, 'Support': supp, 'Num elements': n_elements})\n",
    "df = df.sort_values(by=['Num elements', 'Support'], ascending=False)\n",
    "print(df[:10].set_index('Sequences').to_markdown())\n",
    "\n",
    "df.to_csv('results_time_constraints/results_support_{}.csv'.format(support_percentage))\n",
    "#print(df.set_index('sequences').to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patterns found: 35\n"
     ]
    }
   ],
   "source": [
    "row_with_more_sx = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if \",\" in row['Sequences']:\n",
    "        splitted = row['Sequences'].split(\",\")\n",
    "        if len(set(splitted)) >= 2:\n",
    "            row_with_more_sx += 1\n",
    "\n",
    "print(\"Patterns found: {}\".format(n_pattern_found))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
